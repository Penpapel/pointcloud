<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Depth Estimation with TensorFlow.js</title>
  <!-- Include TensorFlow.js and Three.js -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.20.0/dist/tf.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
  <style>
    body { margin: 0; overflow: hidden; }
    #three-container { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }
  </style>
</head>
<body>

  <!-- Hidden video and canvas elements -->
  <video id="video" autoplay playsinline style="display: none;"></video>
  <canvas id="canvas" style="display: none;"></canvas>
  <!-- Three.js container -->
  <div id="three-container"></div>

  <script>
    let model;
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');

    const scene = new THREE.Scene();
    const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 1, 5000);
    camera.position.z = 1000;
    const renderer = new THREE.WebGLRenderer({ antialias: true });
    renderer.setSize(window.innerWidth, window.innerHeight);
    document.getElementById('three-container').appendChild(renderer.domElement);

    const geometry = new THREE.BufferGeometry();
    const material = new THREE.PointsMaterial({ size: 2, vertexColors: true });
    const points = new THREE.Points(geometry, material);
    scene.add(points);

    async function loadModel() {
      tf.setBackend('webgl');
      await tf.ready();
      model = await tf.loadGraphModel('path/to/model.json');
    }

    function startVideo() {
      navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } })
        .then(stream => {
          video.srcObject = stream;
          video.onloadedmetadata = () => {
            // Set canvas dimensions to match the video
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            startApp();
          };
        })
        .catch(err => {
          console.error('Error accessing camera: ', err);
        });
    }

    function startApp() {
      processFrame();
    }

    async function processFrame() {
      // Draw the current frame to the canvas
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
      const inputImage = tf.browser.fromPixels(canvas);

      // Estimate depth
      const depthData = await estimateDepth(inputImage);

      // Generate and render the point cloud
      generatePointCloud(depthData, imageData);
      renderer.render(scene, camera);

      // Clean up tensors
      inputImage.dispose();

      // Request the next frame
      requestAnimationFrame(processFrame);
    }

    function preprocessImage(image) {
      const resized = tf.image.resizeBilinear(image, [256, 256]);
      const normalized = resized.div(255);
      const batched = normalized.expandDims(0);
      resized.dispose();
      normalized.dispose();
      return batched;
    }

    async function estimateDepth(inputImage) {
      const preprocessed = preprocessImage(inputImage);
      const depthMap = await model.predict(preprocessed);
      const depthData = depthMap.squeeze().dataSync();
      preprocessed.dispose();
      depthMap.dispose();
      return depthData;
    }

    function generatePointCloud(depthData, imageData) {
      const positions = [];
      const colors = [];
      const width = 256;
      const height = 256;
      const samplingRate = 4;

      for (let y = 0; y < height; y += samplingRate) {
        for (let x = 0; x < width; x += samplingRate) {
          const index = y * width + x;
          const depth = depthData[index];

          const z = depth * 500; // Scale depth values

          const pixelX = x * (canvas.width / width);
          const pixelY = y * (canvas.height / height);
          const pixelIndex = (Math.floor(pixelY) * canvas.width + Math.floor(pixelX)) * 4;
          const r = imageData.data[pixelIndex];
          const g = imageData.data[pixelIndex + 1];
          const b = imageData.data[pixelIndex + 2];

          positions.push(pixelX - canvas.width / 2);
          positions.push(-(pixelY - canvas.height / 2));
          positions.push(-z);

          colors.push(r / 255);
          colors.push(g / 255);
          colors.push(b / 255);
        }
      }

      geometry.setAttribute('position', new THREE.Float32BufferAttribute(positions, 3));
      geometry.setAttribute('color', new THREE.Float32BufferAttribute(colors, 3));

      geometry.attributes.position.needsUpdate = true;
      geometry.attributes.color.needsUpdate = true;
    }

    window.addEventListener('load', async () => {
      await loadModel();
      startVideo();
    });

    // Handle window resize
    window.addEventListener('resize', () => {
      camera.aspect = window.innerWidth / window.innerHeight;
      camera.updateProjectionMatrix();
      renderer.setSize(window.innerWidth, window.innerHeight);
    });
  </script>

</body>
</html>
